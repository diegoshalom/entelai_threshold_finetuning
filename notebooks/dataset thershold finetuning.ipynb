{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47fcacf6-37a5-4ac3-b6d1-33baeac7f000",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Cargo packages e inicializo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b1a8220-ba03-4cb7-b2df-b3b7e683ae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import fcnAFIL\n",
    "import lesion_classifiers as lc\n",
    "import time\n",
    "import SimpleITK as sitk\n",
    "\n",
    "if os.environ['COMPUTERNAME']=='DIEGO-DESKTOP':\n",
    "    datadir = 'E:/Entelai/DATA/threshold_finetuning/data completa'\n",
    "    codedir = 'E:/REPOS/entelai_threshold_finetuning/'\n",
    "else:\n",
    "    datadir = 'C:/Entelai/DATA/threshold_finetuning/data completa'\n",
    "    codedir = 'C:/REPOS/entelai_threshold_finetuning/'\n",
    "    \n",
    "outdatadir = os.path.join(datadir, 'out')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892f904b-f073-4168-a57b-aa6b37e170b9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Full process, file generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117d8bc7-46c9-4a9b-8194-024eb29db1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PAR = fcnAFIL.build_pairs_theshold_finetuning(datadir)\n",
    "\n",
    "param = {\"thres\":np.nan, \"slope\":np.nan, \"growtype\":\"largesmall_01p\", \\\n",
    "    'fcn_classify_lesions':lc._classify_lesions_6SD,   \\\n",
    "        'condname':'largesmall_01p_new10'}\n",
    "\n",
    "t = time.time()\n",
    "for i, par in enumerate(PAR):\n",
    "    print('Inicio %s'%(par['studiesname']))\n",
    "\n",
    "    if len(par['studies'][0]['lesiones_fname'])==0:\n",
    "        print('Empty filename')\n",
    "        continue\n",
    "   \n",
    "    par = fcnAFIL.full_process_pair(par=par, outdatadir=outdatadir, param=param)\n",
    "\n",
    "    # Delete some memory-consuming keys, to fit in memory\n",
    "    if 'index' in par:\n",
    "        del par['index']    \n",
    "    for ind, study in enumerate(par['studies']):\n",
    "        for keyremove in ['img', 'array', 'labels', 'volumen',\n",
    "                            'lblchanges', 'relabeled']: # for back compatibility\n",
    "            if keyremove in par['studies'][ind]:\n",
    "                del par['studies'][ind][keyremove]\n",
    "\n",
    "    PAR[i] = par\n",
    "\n",
    "    t1 = time.time() - t\n",
    "    # print(par)\n",
    "    print(\"     Fin %s %2.2fs %s\" % (par['studiesname'], t1, param['condname']))\n",
    "\n",
    "np.savez_compressed(os.path.join(datadir,'PARES_threshold_finetuning.npz'), PAR=PAR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0d86a3-286b-4c2e-a622-c540dc258d37",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Cargo file generado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29cee712-c2b6-4a58-9757-75063e8e18eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = np.load(os.path.join(datadir,'PARES_threshold_finetuning.npz'), allow_pickle=True)\n",
    "loaded.files\n",
    "PAR = list(loaded['PAR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0478b7-cda0-4c9d-80fd-fc3a2473c34b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Genero planilla unificada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cfc4ffe-0b77-40de-9f70-e31a654f041b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listo\n"
     ]
    }
   ],
   "source": [
    "subject = []\n",
    "id = []\n",
    "v1 = []\n",
    "v2 = []\n",
    "for par in PAR:\n",
    "    if not('LVTM' in par):\n",
    "        continue\n",
    "    lvtm = par['LVTM']\n",
    "    for row in lvtm:\n",
    "        subject.append(par['studiesname'])\n",
    "        id.append(row[0])\n",
    "        v1.append(row[1])\n",
    "        v2.append(row[2])\n",
    "\n",
    "df = pd.DataFrame(list(zip(subject,id,v1,v2)), columns=['subject','id','v1','v2'])\n",
    "\n",
    "fcns = [lc._classify_lesions_4tau_samereso, lc._classify_lesions_6tau_samereso ,lc._classify_lesions_6tau_diffreso]\n",
    "fcnnames = ['cat 4tau','cat 6tau samereso','cat 6tau diffreso']\n",
    "for fcn,name in zip(fcns,fcnnames):\n",
    "    index = fcn(df.v1,df.v2)\n",
    "    categ = index['grow']*1+index['stable']*2+index['new']*3\n",
    "    categs = ('error', 'grow', 'stable', 'new')    \n",
    "    for i in range(len(categ)):\n",
    "        categ[i]=categs[categ[i]]\n",
    "\n",
    "    df[name] = categ\n",
    "df.to_excel(os.path.join(outdatadir,'dataset_threshold_finetuning_all_lesions.xlsx'),index=False)\n",
    "print('Listo')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
