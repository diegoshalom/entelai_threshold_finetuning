{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53eb3184-9983-4a66-bf11-7b6444889862",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Cargo packages e inicializo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1abeebdd-5d4a-4248-80a5-0d3dca0301f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %% Preparo todo, cargo packages\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import fcnAFIL\n",
    "import lesion_classifiers as lc\n",
    "import time\n",
    "import SimpleITK as sitk\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import norm\n",
    "\n",
    "            \n",
    "\n",
    "if os.environ['COMPUTERNAME']=='DIEGO-DESKTOP':\n",
    "    datadir = 'E:/Entelai/DATA/Dataset 6x24'\n",
    "    codedir = 'E:/REPOS/entelai_threshold_finetuning/'\n",
    "else:\n",
    "    datadir = 'C:/Entelai/DATA/Dataset_6x4_24'\n",
    "    codedir = 'C:/REPOS/entelai_threshold_finetuning/'\n",
    "    \n",
    "outdatadir = os.path.join(datadir, 'out')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea88394-3205-45d9-a482-f6cc95b370dd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Armo PARES y guardo file (una vez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f67b8fd-4f5d-4603-9dfa-592db8ed181a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %% Armo y proceso pares y guardo file\n",
    "param = {\"thres\":np.nan, \"slope\":np.nan, \"growtype\":\"largesmall_01p\", \\\n",
    "    'fcn_classify_lesions':lc.classify_lesion_largesmall_01p_new10, \\\n",
    "        'condname':'largesmall_01p_new10'}\n",
    "\n",
    "ST = fcnAFIL.build_structure_ST_6x4(datadir)\n",
    "PAR = fcnAFIL.build_pairs_of_studies_6x4(ST)    \n",
    "\n",
    "# PAR = [par for par in PAR if par['samereso']==True and par['samesubj']==True]        \n",
    "PAR = [par for par in PAR if par['samesubj']==True]        \n",
    "\n",
    "t = time.time()\n",
    "for i, par in enumerate(PAR):\n",
    "    par = fcnAFIL.full_process_pair(par=par, outdatadir=outdatadir, param=param)\n",
    "\n",
    "    # Delete some memory-consuming keys, to fit in memory\n",
    "    if 'index' in par:\n",
    "        del par['index']    \n",
    "    for ind, study in enumerate(par['studies']):\n",
    "        for keyremove in ['img', 'array', 'labels', 'volumen',\n",
    "                            'lblchanges', 'relabeled']: # for back compatibility\n",
    "            if keyremove in par['studies'][ind]:\n",
    "                del par['studies'][ind][keyremove]\n",
    "\n",
    "    PAR[i] = par\n",
    "\n",
    "    t1 = time.time() - t\n",
    "    print(\"%d/%d %s %2.2fs %s\" % (i,len(PAR),par['studiesname'], t1, param['condname']))\n",
    "print('Listo')\n",
    "np.savez_compressed(os.path.join(datadir,'PARES_6x4.npz'), PAR=PAR)\n",
    "# loaded = np.load(os.path.join(datadir,'PARES_6x4.npz'), allow_pickle=True)\n",
    "# loaded.files\n",
    "# PAR = list(loaded['PAR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e591c27f-9195-4814-b780-21afe29b1953",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Cargo file generado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e37b52e5-975b-4ba0-b1d3-6635e7878d73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "# %% cargo file\n",
    "loaded = np.load(os.path.join(datadir,'PARES_6x4.npz'), allow_pickle=True)\n",
    "loaded.files\n",
    "PAR = list(loaded['PAR'])\n",
    "print(len(PAR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978c7722-8659-4a7f-8c5a-c57509d6e120",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Genero planilla unificada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "639ec356-c001-4e2f-b6e5-0fa97b00abd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listo\n"
     ]
    }
   ],
   "source": [
    "subject = []\n",
    "samereso = []\n",
    "id = []\n",
    "v1 = []\n",
    "v2 = []\n",
    "for par in PAR:\n",
    "    lvtm = par['LVTM']\n",
    "    for row in lvtm:\n",
    "        subject.append(par['subject'])\n",
    "        samereso.append(par['samereso'])\n",
    "        id.append(row[0])\n",
    "        v1.append(row[1])\n",
    "        v2.append(row[2])\n",
    "\n",
    "df = pd.DataFrame(list(zip(subject,samereso,id,v1,v2)), columns=['subject','samereso','id','v1','v2'])\n",
    "\n",
    "fcns = [lc._classify_lesions_4tau_samereso, lc._classify_lesions_6tau_samereso ,lc._classify_lesions_6tau_diffreso]\n",
    "fcnnames = ['cat 4tau','cat 6tau samereso','cat 6tau diffreso']\n",
    "for fcn,name in zip(fcns,fcnnames):\n",
    "    index = fcn(df.v1,df.v2)\n",
    "    categ = index['grow']*1+index['stable']*2+index['new']*3\n",
    "    categs = ('error', 'grow', 'stable', 'new')    \n",
    "    for i in range(len(categ)):\n",
    "        categ[i]=categs[categ[i]]\n",
    "\n",
    "    df[name] = categ\n",
    "df.to_excel(os.path.join(outdatadir,'dataset_6x4_all_lesions.xlsx'),index=False)\n",
    "print('Listo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be6c11e-54c7-41b4-9407-668167d0b503",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Defino funciones de ploteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae19f27-2e54-4b20-90ec-3fc6a6950e3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %% Defino funciones de ploteo\n",
    "\n",
    "def df_extract_vp_dvp(PAR,samereso):\n",
    "    vol1 = np.array([])\n",
    "    vol2 = np.array([])\n",
    "    sid = np.array([])\n",
    "    samereso = np.array([])\n",
    "    for par in PAR:\n",
    "        if 'LVTM' not in par:\n",
    "            continue\n",
    "        # if 'samereso' in par:\n",
    "        #     if par['samereso'] not in samereso:\n",
    "        #         continue  \n",
    "        item = par['LVTM']\n",
    "        vol1 = np.append(vol1,item[:,1])\n",
    "        vol2 = np.append(vol2,item[:,2])\n",
    "        ndata = len(item[:,2])\n",
    "        sid = np.append(sid,np.repeat(par['studies'][0]['subject'],ndata))\n",
    "        samereso = np.append(samereso,np.repeat(par['samereso'],ndata))\n",
    "\n",
    "    df = pd.DataFrame([vol1,vol2,sid,samereso],index=['vol1','vol2','sid','samereso']).T\n",
    "   \n",
    "    df['vp'] = (df['vol2']+df['vol1'])/2.\n",
    "    df['dvp'] = (df['vol2']-df['vol1'])/df['vp']*100.\n",
    "    df = df.sort_values('vp')\n",
    "\n",
    "    df = df[(df.vol1>0) & (df.vol2>0)]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def plotv1v2(v1,v2,maxx):\n",
    "    plt.plot(v1,v2,'.')\n",
    "    plt.axis('square')\n",
    "    plt.xlim([0,maxx])\n",
    "    plt.ylim([0,maxx])\n",
    "    plt.grid(True)\n",
    "    x = np.linspace (0,maxx,1000)\n",
    "    plt.plot(x, x, 'k--',linewidth=0.5)\n",
    "    plt.xlabel('V$_1$ [mm$^3$]')\n",
    "    plt.ylabel('V$_2$ [mm$^3$]')\n",
    "\n",
    "def plotdvpdv(v1,v2):\n",
    "    vp = (v2+v1)/2.\n",
    "    dvp = (v2-v1)/vp*100\n",
    "    plt.plot(dvp,vp,'.')\n",
    "    plt.xlim([-200,200])\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"% change volume\")\n",
    "    plt.ylabel(\"Mean volume [mm$^3$]\")\n",
    "\n",
    "    \n",
    "def plot_v1v2_dvpdv(v1,v2,samereso):\n",
    "    v1 = np.array(v1)\n",
    "    v2 = np.array(v2)\n",
    "    maxx = max(max(v1),max(v2))*1.05\n",
    "    \n",
    "    plt.figure()\n",
    "    h=dict()\n",
    "    h['fig'] = plt.gcf()\n",
    "    h['fig'].set_size_inches(7, 7)    \n",
    "    \n",
    "    h['h1'] = plt.subplot(221)\n",
    "    # plotv1v2(v1,v2,maxx)\n",
    "    plotv1v2(v1[samereso==0],v2[samereso==0],maxx)\n",
    "    plotv1v2(v1[samereso==1],v2[samereso==1],maxx)\n",
    "    \n",
    "\n",
    "    h['h2'] = plt.subplot(222)\n",
    "    # plotv1v2(v1,v2,maxx*1.3)\n",
    "    plotv1v2(v1[samereso==0],v2[samereso==0],maxx*1.3)\n",
    "    plotv1v2(v1[samereso==1],v2[samereso==1],maxx*1.3)   \n",
    "    \n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.xlim([.7,maxx*1.3])\n",
    "    plt.ylim([.7,maxx*1.3])    \n",
    "\n",
    "    h['h3'] = plt.subplot(223)\n",
    "    # plotdvpdv(v1,v2)\n",
    "    plotdvpdv(v1[samereso==0],v2[samereso==0])\n",
    "    plotdvpdv(v1[samereso==1],v2[samereso==1])\n",
    "\n",
    "    h['h4'] = plt.subplot(224)\n",
    "    plotdvpdv(v1[samereso==0],v2[samereso==0])\n",
    "    plotdvpdv(v1[samereso==1],v2[samereso==1])    \n",
    "    # plotdvpdv(v1,v2)\n",
    "    plt.yscale('log')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return h\n",
    "\n",
    "def plot_v1v2_4escalas(v1,v2):\n",
    "    v1 = np.array(v1)\n",
    "    v2 = np.array(v2)\n",
    "    maxx = max(max(v1),max(v2))*1.05\n",
    "    \n",
    "    plt.figure()\n",
    "    h=dict()\n",
    "    h['fig'] = plt.gcf()\n",
    "    h['fig'].set_size_inches(7, 7)    \n",
    "    \n",
    "    h['h1'] = plt.subplot(221)\n",
    "    plotv1v2(v1,v2,maxx)\n",
    "    plt.xlim([0, 100])\n",
    "    plt.ylim([0, 100])\n",
    "\n",
    "    h['h2'] = plt.subplot(222)\n",
    "    plotv1v2(v1,v2,maxx)\n",
    "    plt.xlim([0, 250])\n",
    "    plt.ylim([0, 250])\n",
    "\n",
    "    h['h3'] = plt.subplot(223)\n",
    "    plotv1v2(v1,v2,maxx)\n",
    "    plt.xlim([0, 1000])\n",
    "    plt.ylim([0, 1000])\n",
    "    \n",
    "    h['h4'] = plt.subplot(224)\n",
    "    plotv1v2(v1,v2,maxx)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return h\n",
    "\n",
    "def AgregoCte(h1s,h2s):\n",
    "    for ax in h1s:\n",
    "        plt.sca(h[ax])\n",
    "        maxx = max(plt.ylim())\n",
    "        x = np.linspace (0,maxx,1000)\n",
    "        x = np.logspace(-1,5,100)\n",
    "        plt.plot(x, x + 48, 'r',label=\"cte=48\")\n",
    "        \n",
    "    for ax in h2s:\n",
    "        plt.sca(h[ax])\n",
    "        ylim = plt.ylim()\n",
    "        x = np.logspace(-1,5,100)\n",
    "        plt.plot(100*1/((x/48)+.5),x,'r',linewidth=2)\n",
    "        plt.ylim(ylim)    \n",
    "\n",
    "def Agrego2sdSmallLarge(h1s,h2s,umbral, sd1,sd2):    \n",
    "    for ax in h1s:\n",
    "        plt.sca(h[ax])\n",
    "        maxx = max(plt.ylim())\n",
    "        \n",
    "        x = np.linspace (0,umbral,1000)\n",
    "        y = x*(1+nstd*sd1/100)\n",
    "        plt.plot(x, y, 'g')\n",
    "        plt.plot([umbral, umbral],[umbral,umbral*(1+nstd*sd1/100)],'--g')\n",
    "        plt.plot([umbral, umbral],[0,maxx],'--g')\n",
    "        x = np.linspace (umbral,maxx,1000)\n",
    "        y = x*(1+nstd*sd2/100)\n",
    "        plt.plot(x, y, 'g',label=\"sd(%Vc) small/large\")\n",
    "    \n",
    "    for ax in h2s:\n",
    "        plt.sca(h[ax])\n",
    "        ylim = plt.ylim()\n",
    "    \n",
    "        plt.plot([-nstd*sd1,nstd*sd1],[umbral, umbral],'--g')\n",
    "        plt.plot([nstd*sd1,nstd*sd1],[.1, umbral],'g')\n",
    "        plt.plot([-nstd*sd1,-nstd*sd1],[.1, umbral],'g')\n",
    "        plt.plot([nstd*sd2,nstd*sd2],[1e4, umbral],'g')\n",
    "        plt.plot([-nstd*sd2,-nstd*sd2],[1e4, umbral],'g')\n",
    "        plt.ylim(ylim)  \n",
    "        \n",
    "def Agrego2sdExpFit(h1s,h2s,popt):    \n",
    "    for ax in h1s:\n",
    "        plt.sca(h[ax])\n",
    "        maxx = max(plt.ylim())\n",
    "        x = np.linspace (0,maxx,1000)\n",
    "        plt.plot(x, x*(1+nstd*func(x,*popt)/100), 'c',linewidth=2,label=\"Exp fit of in sd(%Vc)\")\n",
    "    \n",
    "    for ax in h2s:\n",
    "        plt.sca(h[ax])\n",
    "        maxx = max(plt.ylim())\n",
    "        \n",
    "        x=range(0,int(maxx))\n",
    "        plt.plot(nstd*func(x,*popt),x, 'c',linewidth=2)\n",
    "\n",
    "def AgregoRecta(h1s,h2s,P,pend):    \n",
    "    v1 = np.linspace (0,65,66)\n",
    "    v2 = P + pend*v1\n",
    "    vp = (v2+v1)/2.\n",
    "    dvp = (v2-v1)/vp*100    \n",
    "    for ax in h1s:\n",
    "        plt.sca(h[ax])        \n",
    "        plt.plot(v1,v2,'r')        \n",
    "    \n",
    "    for ax in h2s:\n",
    "        plt.sca(h[ax])             \n",
    "        plt.plot(dvp,vp, 'r',linewidth=2)\n",
    "\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca67ed8-ef79-45da-82fe-4de8e2caa1b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import label\n",
    "from ismember import ismember\n",
    "import pandas as pd\n",
    "from scipy.ndimage import convolve\n",
    "import matplotlib.pyplot as plt \n",
    "from AFIL_to_insert_in_pipeline import calculate_volume_labels\n",
    "\n",
    "# def AFIL_inf(mri_img1: MRIImage, mri_img2: MRIImage, classify_lesions):\n",
    "def AFIL_inf(img1, img2, classify_lesions):\n",
    "\n",
    "    \"\"\"\n",
    "    Automatic Follow-up of Individual Lesions (AFIL)\n",
    "    Calculate and classify lesions\n",
    "    Parameters\n",
    "    ----------\n",
    "    img1, img2: sitkimages of lesions\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    imgout1, imgout2: sitk images of segmentations, labeled as:\n",
    "        1=new\n",
    "        2=resolving\n",
    "        3=small\n",
    "        4=growing\n",
    "        5=stable\n",
    "    \"\"\"\n",
    "    \n",
    "    # img1 = mri_img1.sitk_img\n",
    "    # img2 = mri_img2.sitk_img\n",
    "    array1 = sitk.GetArrayFromImage(img1) != 0\n",
    "    array2 = sitk.GetArrayFromImage(img2) != 0\n",
    "    \n",
    "#     myarray = array1[:,:,120]\n",
    "#     plt.figure()\n",
    "#     plt.subplot(121)\n",
    "#     plt.imshow(myarray)\n",
    "#     # plt.colorbar()\n",
    "#     plt.ylim([100,115])\n",
    "#     plt.xlim([100,117])\n",
    "#     plt.title(\"Original\")\n",
    "#     plt.axis('off')\n",
    "\n",
    "#     print(myarray.shape)\n",
    "#     k = np.array([[0,1,0],[1,1,1],[0,1,0]])\n",
    "#     myarray2 = convolve(myarray,k)\n",
    "#     plt.subplot(122)\n",
    "#     plt.imshow(myarray*.2+myarray2*.8)\n",
    "#     # plt.colorbar()  \n",
    "#     plt.ylim([100,115])\n",
    "#     plt.xlim([100,117])\n",
    "#     plt.title(\"Inflada\")\n",
    "#     plt.axis('off')\n",
    "    \n",
    "    k = np.array([[[0,0,0],[0,1,0],[0,0,0]],[[0,1,0],[1,1,1],[0,1,0]],[[0,0,0],[0,1,0],[0,0,0]]])\n",
    "    array1inf = convolve(array1,k,mode='constant', cval=0)\n",
    "    array2inf = convolve(array2,k,mode='constant', cval=0)\n",
    "    \n",
    "    matrix4dinf = np.stack((array1inf, array2inf))\n",
    "    \n",
    "    labelsinf, numlabels = label(matrix4dinf)\n",
    "    \n",
    "    labels1inf = labelsinf[0, :, :, :]\n",
    "    labels2inf = labelsinf[1, :, :, :]\n",
    "    labels1 = np.multiply(labels1inf,array1)\n",
    "    labels2 = np.multiply(labels2inf,array1)\n",
    "    \n",
    "    vol1inf, x = calculate_volume_labels(labels1inf, numlabels)\n",
    "    vol2inf, x = calculate_volume_labels(labels2inf, numlabels)\n",
    "    vol1, x = calculate_volume_labels(labels1, numlabels)\n",
    "    vol2, x = calculate_volume_labels(labels2, numlabels)\n",
    "\n",
    "    index = classify_lesions(vol1, vol2,0,0)\n",
    "    indexinf = classify_lesions(vol1inf, vol2inf,0,0)\n",
    "\n",
    "    \n",
    "    Imout = [0, 0]    \n",
    "#     for indim, Im in enumerate([labels1, labels2]):\n",
    "        \n",
    "#         # build array with new=1, res=2, etc\n",
    "#         array = np.zeros_like(Im)\n",
    "#         for lab, j in zip(['grow', 'stable', 'new'],\n",
    "#                          [1, 2, 3]):\n",
    "#             array += j * ismember(Im, 1+np.where(index[lab])[0])[0]\n",
    "            \n",
    "#         imgoverlay = sitk.Cast(sitk.GetImageFromArray(array), sitk.sitkUInt8)\n",
    "#         imgoverlay.CopyInformation(img1)\n",
    "#         Imout[indim] = imgoverlay\n",
    "\n",
    "    x = np.array(range(1,1+len(vol1)))\n",
    "    LVTM = np.transpose(np.stack([x, vol1, vol2, vol1inf, vol2inf])) # Label Volume Tracking Matrix\n",
    "    LVTM = list(LVTM) # una lista de nparrays\n",
    "    categ = index['grow']*1+index['stable']*2+index['new']*3\n",
    "    categinf = indexinf['grow']*1+indexinf['stable']*2+indexinf['new']*3\n",
    "\n",
    "    categs = ('error', 'grow', 'stable', 'new')    \n",
    "    \n",
    "    for i,lv in enumerate(LVTM):\n",
    "        temp =list(lv)\n",
    "        temp.append(categs[categ[i]])\n",
    "        temp.append(categs[categinf[i]])\n",
    "        LVTM[i] = temp\n",
    "    \n",
    "    df = pd.DataFrame(LVTM, columns=['id', 'v1', 'v2', 'v1inf', 'v2inf', 'cat', 'catinf'])\n",
    "\n",
    "    return df,0,0 #, mri_img1.copy_with_new_sitk_img(Imout[0]), mri_img2.copy_with_new_sitk_img(Imout[1])\n",
    "\n",
    "def AFIL(img1, img2, classify_lesions):\n",
    "\n",
    "    \"\"\"\n",
    "    Automatic Follow-up of Individual Lesions (AFIL)\n",
    "    Calculate and classify lesions\n",
    "    Parameters\n",
    "    ----------\n",
    "    img1, img2: sitkimages of lesions\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    imgout1, imgout2: sitk images of segmentations, labeled as:\n",
    "        1=new\n",
    "        2=resolving\n",
    "        3=small\n",
    "        4=growing\n",
    "        5=stable\n",
    "    \"\"\"\n",
    "    \n",
    "    # img1 = mri_img1.sitk_img\n",
    "    # img2 = mri_img2.sitk_img\n",
    "    array1 = sitk.GetArrayFromImage(img1) != 0\n",
    "    array2 = sitk.GetArrayFromImage(img2) != 0\n",
    "    \n",
    "    matrix4d = np.stack((array1, array2))\n",
    "    \n",
    "    labels, numlabels = label(matrix4d)\n",
    "    \n",
    "    labels1 = labels[0, :, :, :]\n",
    "    labels2 = labels[1, :, :, :]\n",
    "    \n",
    "    vol1, x = calculate_volume_labels(labels1, numlabels)\n",
    "    vol2, x = calculate_volume_labels(labels2, numlabels)\n",
    "\n",
    "    index = classify_lesions(vol1, vol2,0,0)\n",
    "\n",
    "    Imout = [0, 0]    \n",
    "#     for indim, Im in enumerate([labels1, labels2]):\n",
    "        \n",
    "#         # build array with new=1, res=2, etc\n",
    "#         array = np.zeros_like(Im)\n",
    "#         for lab, j in zip(['grow', 'stable', 'new'],\n",
    "#                          [1, 2, 3]):\n",
    "#             array += j * ismember(Im, 1+np.where(index[lab])[0])[0]\n",
    "            \n",
    "#         imgoverlay = sitk.Cast(sitk.GetImageFromArray(array), sitk.sitkUInt8)\n",
    "#         imgoverlay.CopyInformation(img1)\n",
    "#         Imout[indim] = imgoverlay\n",
    "\n",
    "    x = np.array(range(1,1+len(vol1)))\n",
    "    LVTM = np.transpose(np.stack([x, vol1, vol2])) # Label Volume Tracking Matrix\n",
    "    LVTM = list(LVTM) # una lista de nparrays\n",
    "    categ = index['grow']*1+index['stable']*2+index['new']*3\n",
    "\n",
    "    categs = ('error', 'grow', 'stable', 'new')    \n",
    "    \n",
    "    for i,lv in enumerate(LVTM):\n",
    "        temp =list(lv)\n",
    "        temp.append(categs[categ[i]])\n",
    "        LVTM[i] = temp\n",
    "    \n",
    "    df = pd.DataFrame(LVTM, columns=['id', 'v1', 'v2', 'cat'])\n",
    "\n",
    "    return df,0,0 #, mri_img1.copy_with_new_sitk_img(Imout[0]), mri_img2.copy_with_new_sitk_img(Imout[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557b8e29-e6c8-48c9-8da4-c14c672c2d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['stable','grow','new']\n",
    "print(' ' + str(cats))\n",
    "# classify_lesions = lesions._classify_lesions_6tau_samereso\n",
    "classify_lesions = lc._classify_lesions_4tau\n",
    "\n",
    "# for pat in [patients[0]]:\n",
    "#     filename1 = '/mnt/c/Entelai/DATA/threshold_finetuning/data completa/out/%d/lesiones_1.nii.gz'%(pat)\n",
    "#     filename2 = '/mnt/c/Entelai/DATA/threshold_finetuning/data completa/out/%d/lesiones_2.nii.gz'%(pat)\n",
    "for par in PAR:\n",
    "    # if not par['samereso']:\n",
    "    #     continue\n",
    "    \n",
    "    pat = par['subject']\n",
    "    filename1 = par['studies'][0]['lesiones_fname']\n",
    "    filename2 = par['studies'][1]['lesiones_fname']\n",
    "\n",
    "    img1 = sitk.ReadImage(filename1)\n",
    "    img2 = sitk.ReadImage(filename2)\n",
    "    \n",
    "    \n",
    "    lesion_tableinf, img_overlay1, img_overlay2 = AFIL_inf(img1, img2, classify_lesions)\n",
    "    print(\"inf\",pat,end=\" \")\n",
    "    for cat in cats: \n",
    "        print(sum(lesion_tableinf.cat == cat),end=\"   \")\n",
    "    print(\" \",par['samereso'],par['samesubj'])\n",
    "\n",
    "    lesion_table, img_overlay1, img_overlay2 = AFIL(img1, img2, classify_lesions)\n",
    "    \n",
    "    print(\"com\",pat,end=\" \")\n",
    "    for cat in cats: \n",
    "        print(sum(lesion_table.cat == cat),end=\"   \")\n",
    "    print(\" \")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135e335e-1d59-4108-9426-d24bb2c0f98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "par['samereso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3844a606-301b-4453-b50d-73d2e9ae82dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "loaded = np.load(os.path.join(datadir,'PARES_6x4.npz'), allow_pickle=True)\n",
    "loaded.files\n",
    "PAR = list(loaded['PAR'])\n",
    "\n",
    "nstd = 2.32634\n",
    "nstd = 3\n",
    "nstd = 6\n",
    "\n",
    "samereso = [True]\n",
    "samereso = [False]\n",
    "# samereso = [True, False]\n",
    "\n",
    "\n",
    "df = df_extract_vp_dvp(PAR,samereso)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59312cb2-50c7-4680-8c61-a719e4640452",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = plot_v1v2_dvpdv(df.vol1,df.vol2,df.samereso)\n",
    "h['h3'].legend(('Diff Reso','Same Reso'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9391f8ce-c7ca-4d50-9a19-b5bfa4a6dc8a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Corro graficos viejo, en el .py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df234e35-bedc-4de0-8c1f-355869eb8cfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %% exponencial stdev of %Vc vs mean volume\n",
    "\n",
    "loaded = np.load(os.path.join(datadir,'PARES_6x4.npz'), allow_pickle=True)\n",
    "loaded.files\n",
    "PAR = list(loaded['PAR'])\n",
    "\n",
    "nstd = 2.32634\n",
    "nstd = 3\n",
    "nstd = 6\n",
    "\n",
    "samereso = [True]\n",
    "samereso = [False]\n",
    "# samereso = [True, False]\n",
    "\n",
    "vp, dvp, vol1, vol2 = extract_vp_dvp(PAR,samereso)\n",
    "\n",
    "###########################################\n",
    "### Armo tabla sd(%Vc) small/large\n",
    "\n",
    "tabla=[]\n",
    "for umbral in [10,20,30,40,48,50,65,100,200,300,400,500,1000]:\n",
    "    # umbral = 50\n",
    "    data1 = [val[1] for val in zip(vp,dvp) if val[0]<=umbral]\n",
    "    sd1 = np.std(data1)\n",
    "    data2 = [val[1] for val in zip(vp,dvp) if val[0]>umbral]\n",
    "    sd2 = np.std(data2)    \n",
    "    print(\"%d %2.4f (%d) %2.4f (%d)\"%(umbral,sd1,len(data1),sd2,len(data2)))\n",
    "    tabla.append({'thres':umbral,'sd1':sd1,'n1':len(data1),'sd2':sd2,'n2':len(data2)})\n",
    "\n",
    "umbral = 65\n",
    "tablaumbral = [item for item in tabla if item['thres']==umbral ][0]\n",
    "\n",
    "##########  Ajuste exponencial STD de %VC to mean volume\n",
    "plt.figure(100)\n",
    "ventana = 50\n",
    "nventanas = 100\n",
    "x=np.zeros(nventanas)\n",
    "x[:] = np.nan\n",
    "y=np.zeros(nventanas)\n",
    "x[:] = np.nan\n",
    "for i in range(nventanas):\n",
    "    desde = int(i*np.floor((len(vp)-ventana)/nventanas))\n",
    "    hasta = desde + ventana        \n",
    "    x[i] = np.mean(vp[desde:hasta])\n",
    "    y[i] = np.std(dvp[desde:hasta])\n",
    "    \n",
    "def func(x, a, b, c):\n",
    "    return a * np.exp(-b * x) + c\n",
    "\n",
    "maxx = max(x)*1.05 \n",
    "plt.plot(x,y,'.',label='data')    \n",
    "popt, pcov = curve_fit(func, x, y)\n",
    "# plt.plot(x,y-func(x, *popt),'.',label='Residuos')\n",
    "print(\"el desvío de los residuos es %g\" % np.std(y-func(x, *popt)))\n",
    "print(\"valor de la exonencial en 3tau es %g\" % (float(func(65, *popt))-float(popt[2])))\n",
    "\n",
    "p_sigma = np.sqrt(np.diag(pcov))\n",
    "x = np.linspace(0,maxx,1000)\n",
    "plt.plot(x, func(x, *popt), 'c-',\n",
    "         label='fit: a=%5.3f, b=%5.3f, c=%5.3f' % tuple(popt))\n",
    "plt.legend()\n",
    "plt.xlabel('Mean volume [mm$^3$]')\n",
    "plt.ylabel('stdev of %Vc')\n",
    "plt.grid(True)\n",
    "plt.xlim([0 ,maxx])\n",
    "plt.title('Umbral = 3/b = %2.3f mm$^3$' %  (3/popt[1]))\n",
    "umbral = np.floor(3/popt[1])\n",
    "myylim = plt.ylim()\n",
    "plt.plot([umbral, umbral],myylim,'--g')\n",
    "plt.ylim(myylim)\n",
    "\n",
    "plt.figure(101)\n",
    "ventana = 50\n",
    "nventanas = 100\n",
    "x=np.zeros(nventanas)\n",
    "x[:] = np.nan\n",
    "y=np.zeros(nventanas)\n",
    "x[:] = np.nan\n",
    "for i in range(nventanas):\n",
    "    desde = int(i*np.floor((len(vp)-ventana)/nventanas))\n",
    "    hasta = desde + ventana        \n",
    "    x[i] = np.mean(vp[desde:hasta])\n",
    "    y[i] = np.std(dvp[desde:hasta])\n",
    "    \n",
    "maxx = max(x)*1.05 \n",
    "plt.plot(x,y,'.',label='data')    \n",
    "x = np.linspace(0,maxx,1000)\n",
    "\n",
    "\n",
    "\n",
    "sd1 = tablaumbral['sd1']\n",
    "# plt.plot([0,umbral],[sd1, sd1],'g')\n",
    "sd2 = tablaumbral['sd2']\n",
    "plt.plot([umbral,maxx],[sd2,sd2],'g')\n",
    "ylim = plt.ylim()\n",
    "plt.plot([umbral,umbral],plt.ylim(),'--g')\n",
    "plt.ylim(ylim) \n",
    "\n",
    "plt.xlabel('Mean volume [mm$^3$]')\n",
    "plt.ylabel('stdev of %Vc')\n",
    "plt.grid(True)\n",
    "plt.xlim([0 ,maxx])\n",
    "plt.title('Factor: %2.3f%%'%(sd2))\n",
    "#####################################\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "h = plot_v1v2_dvpdv(vol1,vol2)\n",
    "AgregoCte(['h1','h2'],['h3','h4'])\n",
    "Agrego2sdSmallLarge(['h1','h2'],['h3','h4'],umbral, tablaumbral['sd1'],tablaumbral['sd2'])\n",
    "Agrego2sdExpFit(['h1','h2'],['h3','h4'],popt) \n",
    "\n",
    "h = plot_v1v2_4escalas(vol1,vol2)\n",
    "AgregoCte(['h1','h2','h3','h4'],[])\n",
    "Agrego2sdSmallLarge(['h1','h2','h3','h4'],[],umbral, tablaumbral['sd1'],tablaumbral['sd2'])\n",
    "Agrego2sdExpFit(['h1','h2','h3','h4'],[],popt) \n",
    "\n",
    "\n",
    "\n",
    "mysd = np.zeros(int(umbral))\n",
    "vol1=np.array(vol1)\n",
    "vol2=np.array(vol2)\n",
    "for i in range(1,int(umbral)+1):\n",
    "    data = np.concatenate((vol2[vol1==i], vol1[vol2==i]))\n",
    "    mysd[i-1] = np.std(data) \n",
    "\n",
    "plt.figure(4)\n",
    "plt.subplot(2,1,1)\n",
    "x = np.linspace(1,int(umbral),int(umbral))\n",
    "plt.plot(x,mysd)\n",
    "plt.ylabel('Stdev [mm$^3$]')\n",
    "plt.xlabel('Volume [mm$^3$]')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "h = plt.hist(vol1+vol2,range(0,1+int(umbral)))\n",
    "plt.cla()\n",
    "plt.bar(h[1][:-1],h[0]/len(h[0]),width=1)\n",
    "plt.xlabel('Volume [mm$^3$]')\n",
    "plt.ylabel('Freq')\n",
    "\n",
    "peso = h[0]/sum(h[0])\n",
    "\n",
    "pend_arr = (1+nstd*tablaumbral['sd2']/100)\n",
    "\n",
    "oo = umbral*pend_arr - umbral\n",
    "# La oo la obtengo moviendo el valor para el nstd correspondiente, hasta obtener que val1 == val2\n",
    "if nstd == 4:\n",
    "    oo = 25.365 \n",
    "elif nstd == 3:\n",
    "    oo = 19 \n",
    "else:\n",
    "    oo = 30\n",
    "    \n",
    "U1 = umbral\n",
    "U2 = umbral*(1+nstd*tablaumbral['sd2']/100)\n",
    "pend = (U2-oo)/umbral\n",
    "\n",
    "recta = oo+pend*x\n",
    "fraccarr = (1-norm.cdf(recta,x,np.mean(mysd)))\n",
    "value1 = sum(peso * fraccarr)\n",
    "value2 = 1-norm.cdf(nstd)\n",
    "\n",
    "h = plot_v1v2_4escalas(vol1,vol2)\n",
    "Agrego2sdSmallLarge(['h1','h2','h3','h4'],[],umbral, np.nan,tablaumbral['sd2'])\n",
    "AgregoRecta(['h1','h2','h3','h4'],[],oo,pend)\n",
    "\n",
    "\n",
    "print('Ecuación de la recta 1: V_2C = %g + V1 * %g'%(oo,pend))\n",
    "print('Ecuación de la recta 2: V_2C = V1 * %g'%(pend_arr))\n",
    "print('val1 = %g%% \\nval2 = %g%%'%(value1*100,value2*100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
